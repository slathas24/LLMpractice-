from langchain.text_splitter import RecursiveCharacterTextSplitter

def build_faiss_vector_db(docs: list[Document], save_path: str):
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = splitter.split_documents(docs)

    texts = [doc.page_content for doc in chunks]
    metadatas = [doc.metadata for doc in chunks]
    vectors = []

    for i, text in enumerate(texts):
        if not text.strip(): continue
        try:
            print(f"üîπ Embedding chunk {i+1}/{len(texts)}")
            vector = get_embedding(text)
            vectors.append(vector)
        except Exception as e:
            print(f"‚ùå Error embedding chunk {i}: {e}")
            vectors.append([0.0] * 1536)  # fallback

    assert len(vectors) == len(texts)

    # Wrap back into Document objects
    chunk_docs = [Document(page_content=texts[i], metadata=metadatas[i]) for i in range(len(texts))]
    embedder = ManualEmbedder(vectors)

    vector_db = FAISS.from_documents(chunk_docs, embedding=embedder)
    vector_db.save_local(save_path)
    print(f"‚úÖ Saved vector DB at: {save_path}")
    return vector_db
